<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta name="author" content="Hyung-Kwon Ko">
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Hyung-Kwon Ko's Website</title>

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-0evHe/X+R7YkIZDRvuzKMRqM+OrBnVFBL6DOitfPri4tjfHxaWutUpFmBp4vmVor" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="icon" type="image/x-icon" href="https://cdn-icons-png.flaticon.com/512/141/141791.png">

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Cantarell&family=Pacifico&family=Playfair+Display+SC:wght@900&display=swap"
    rel="stylesheet">
</head>

<body>

  <div class="container text-center mt-5 pt-5" style="max-width: 800px;">
    <h1 class="mb-4 h1-title">Hyung-Kwon Ko</h1>

    <div class="row row-cols-1 row-cols-sm-2 row-cols-md-3 mb-4">
      <div class="col f2 py-1"><a href="./data/hkko_cv.pdf" class="f2">Curriculum Vitae</a></div>
      <div class="col py-1">
        <a href="#" class="cryptedmail f1"
        data-name="hyungkwonko"
        data-domain="gmail"
        data-tld="com"
        onclick="window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld; return false;">
        </a>
      </div>


      

      <div class="col f1 py-1 f1">BLOG (Korean)</div>
      <!-- <div class="col f1 py-1"><a href="https://www.google.com" class="f1">BLOG (Korean)</a></div> -->
    </div>

    <div style="align-items: center;" class="row">
      <div class="col-sm-4">
        <img class="px-2 py-2 img-fluid rounded-circle" src="./images/hkko_grey.jpg"
          onmouseover="this.src='./images/hkko_color.jpg'" onmouseout="this.src='./images/hkko_grey.jpg'">
      </div>
      <div style="text-align: justify;" class="my-4 col-sm-8">
        <p style="border-style: solid; border-color: #2569E6; padding: 10px">
          Currently I'm with <a class="f4" href="https://www.kixlab.org/">KIXLAB</a> at KAIST
          under the supervision of <a class="f4" href="https://juhokim.com/">Prof. Juho Kim</a>.
          I'm working on two HCI projects: 1) "Enabling Prototyping of AI-infused UIs with Task-level Specifications"
          , and 2) "Understanding Artists' Perception, Expectation, and Concern for Large-scale Text-to-Image Generative
          Models", aiming to submit them to
          <a class="f4" href="https://chi2023.acm.org/">CHI 2023</a> and <a class="f4" href="https://iui.acm.org/2023/">IUI 2023</a>, respectively.
        </p>

        <p style="margin-bottom:16px">
          I am broadly interested in Human-Computer Interaction, Human-Centered AI, and Information Visualization.
          I am eager to find important problems in diverse domains, and help people using fancy techniques (it does not
          have to be AI).
          My life-long goal is to found a company with a product that can innovate people's working paradigm, in turn,
          changing their lives more intelligent and convenient.
          I prefer not to draw a strict boundary between academia and industry.
        </p>

        <p style="margin:0px">
          I received my Master's degree from
          <a class="f4" href="https://cse.snu.ac.kr/en">the Department of Computer Science and Engineering</a>
          of
          <a class="f4" href="https://en.snu.ac.kr/">Seoul National University</a> studying Human-computer Interaction
          and Information Visualization.
          During my MS, I worked with
          <a class="f4" href="http://hcil.snu.ac.kr/">SNU HCIL</a>
          under the supervision of
          <a class="f4" href="http://hcil.snu.ac.kr/jwseo/">Prof. Jinwook Seo</a>
          mostly on dimensionality reduction methods.
          I received my Bachelor's degree from
          <a class="f4" href="https://www.hanyang.ac.kr/web/eng">Hanyang University</a>.
          During my BS, I majored in mathematics, minored in industrial engineering, and earned 16 credits in computer
          science and engineering.
          I was a full-time research scientist at
          <a class="f4" href="https://webtoonscorp.com/en/">Naver Webtoon Corp.</a>
        </p>
      </div>
    </div>
  </div>

  <div class="container my-2 py-3" style="max-width: 800px;">
    <h4>NEWS</h4>
    <table style="text-align:justify;" class="table">
      <tbody>
        <tr>
          <td class="px-2" style="width:5%;">Jun</td>
          <td class="px-0" style="width:5%;">2022</td>
          <td style="padding-left:20px; padding-right:0px;">UMATO is accepted to IEEE VIS 2022 short!</td>
        </tr>
        <tr>
          <td class="px-2" style="width:5%;">Jun</td>
          <td class="px-0" style="width:5%;">2022</td>
          <td style="padding-left:20px; padding-right:0px;">Moved to KAIST at Daejeon, Korea to collaborate with KIXLAB
            led by Prof.
            Juho Kim</td>
        </tr>
        <tr>
          <td class="px-2" style="width:5%;">Jan</td>
          <td class="px-0" style="width:5%;">2022</td>
          <td style="padding-left:20px; padding-right:0px;">Published an arxiv paper about interactive brushing
            technique</td>
        </tr>
        <tr>
          <td class="px-2" style="width:5%;">Oct</td>
          <td class="px-0" style="width:5%;">2021</td>
          <td style="padding-left:20px; padding-right:0px;">Got a full-time posiiton as a research scientist at Naver
            Webtoon Corp.</td>
        </tr>
        <tr>
          <td class="px-2" style="width:5%;">Apr</td>
          <td class="px-0" style="width:5%;">2021</td>
          <td style="padding-left:20px; padding-right:0px;">Graduated from Seoul National University receiving Master's
            degree
            in Computer Science and Engineering under the supervision of Prof. Jinwook Seo (specialty: HCI, InfoVis)
          </td>
        </tr>
      </tbody>
    </table>
  </div>

  <div class="container my-2 py-3" style="max-width: 800px;">
    <h4>PUBLICATIONS</h4>
    <table>
      <tbody>
        <tr onmouseout="wetoon_stop()" onmouseover="wetoon_start()" style="vertical-align:top;">
          <td class="py-3 px-2 w-25">
            <div class="one">
              <div class="two" id='wetoon'><video width=100% height=100% muted autoplay loop>
                  <source src="images/wetoon_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video></div>
              <img src='images/wetoon_before.png' class="img1">
            </div>
            <script type="text/javascript">
              function wetoon_start() {
                document.getElementById('wetoon').style.opacity = "1";
              }

              function wetoon_stop() {
                document.getElementById('wetoon').style.opacity = "0";
              }
              wetoon_stop()
            </script>
          </td>
          <td class="py-3 w-75" style="padding-left:15px;">
            <strong>We-toon: A Communication Support System between Writers and
              Artists in Collaborative Webtoon Sketch Revision</strong>
            <br>
            Hyung-Kwon Ko*, Subin An*, Gwanmo Park, Seung Kwon Kim, Daesik Kim, Bohyoung Kim, Jaemin Jo, Jinwook Seo
            <br>
            <em>(Under review)</em>
            <br>
            <div class="d-none d-sm-block">
              <!-- <a class="f3" href="./data/pumap.pdf">paper</a> /
              <a class="f3" href="https://github.com/hyungkwonko/progressive-umap">code</a> /
              <a class="f3" href="https://www.youtube.com/watch?v=_zN-wVwPH1s">video</a> /
              <a class="f3" href="./data/pumap.bib">bibtex</a> /
              <a class="f3" href="https://doi.org/10.2312/evs.20201061">doi</a> -->
              <p style="font-size:11px; margin:0px; text-align:justify;">We present a communication support system,
                namely We-toon, that
                can bridge the webtoon writers and artists during sketch revision
                (i.e., character design and draft revision). In the highly iterative design process between the webtoon
                writers and artists, writers often
                have difficulties in precisely articulating their feedback on sketches
                owing to their lack of drawing proficiency. This drawback makes
                the writers rely on textual descriptions and reference images found
                using search engines, leading to indirect and inefficient communications. Inspired by a formative study,
                we designed We-toon to help
                writers revise webtoon sketches and effectively communicate with
                artists. Through a GAN-based image synthesis and manipulation,
                We-toon can interactively generate diverse reference images and
                synthesize them locally on any user-provided image. Our user study
                with 24 professional webtoon authors demonstrated that We-toon
                outperforms the traditional methods in terms of communication
                effectiveness and the writersâ€™ satisfaction level related to the revised
                image.</p>
            </div>
          </td>
        </tr>

        <tr onmouseout="umato_stop()" onmouseover="umato_start()" style="vertical-align:top;">
          <td class="py-3 px-2 w-25">
            <div class="one">
              <div class="two" id="umato_image" style="opacity: 0;">
                <img src="./images/umato_after.png" class="img1">
              </div>
              <img src="./images/umato_before.png" class="img1">
            </div>
            <script type="text/javascript">
              function umato_start() {
                document.getElementById('umato_image').style.opacity = "1";
              }

              function umato_stop() {
                document.getElementById('umato_image').style.opacity = "0";
              }
              umato_stop()
            </script>
          </td>
          <td class="py-3 w-75" style="padding-left:15px;">
            <strong>Uniform Manifold Approximation with Two-phase Optimization</strong>
            <br>
            Hyeon Jeon*, Hyung-Kwon Ko*, Soohyun Lee, Jaemin Jo, Jinwook Seo
            <br>
            <em>VIS 2022 short (to appear)</em>
            <br>
            <div class="d-none d-sm-block">
              <!-- <a href="http://yenchenlin.me/nerf-supervision/">project page</a> / -->
              <a class="f3" href="https://arxiv.org/abs/2205.00420">paper</a> /
              <a class="f3" href="https://github.com/hyungkwonko/umato">code</a>
              <p style="font-size:11px; margin:0px; text-align:justify;">We introduce Uniform Manifold Approximation
                with Two-phase Optimization (UMATO), a dimensionality reduction (DR) technique that improves UMAP to
                capture the global structure of high-dimensional data more accurately. In UMATO, optimization is divided
                into two phases so that the resulting embeddings can depict the global structure reliably while
                preserving the local structure with sufficient accuracy. As the first phase, hub points are identified
                and projected to construct a skeletal layout for the global structure. In the second phase, the
                remaining points are added to the embedding preserving the regional characteristics of local areas.
                Through quantitative experiments, we found that UMATO (1) outperformed widely used DR techniques in
                preserving the global structure while (2) producing competitive accuracy in representing the local
                structure. We also verified that UMATO is preferable in terms of robustness over diverse initialization
                methods, number of epochs, and subsampling techniques.
              </p>
            </div>
          </td>
        </tr>

        <tr onmouseout="brush_stop()" onmouseover="brush_start()" style="vertical-align:top;">
          <td class="py-3 px-2 w-25">
            <div class="one">
              <div class="two" id="brush_image" style="opacity: 0;">
                <img src="./images/brush_after.png" class="img1">
              </div>
              <img src="./images/brush_before.png" class="img1">
            </div>
            <script type="text/javascript">
              function brush_start() {
                document.getElementById('brush_image').style.opacity = "1";
              }

              function brush_stop() {
                document.getElementById('brush_image').style.opacity = "0";
              }
              brush_stop()
            </script>
          </td>
          <td class="py-3 w-75" style="padding-left:15px;">
            <strong>Distortion-Aware Brushing for Interactive Cluster Analysis in Multidimensional Projections</strong>
            <br>
            Hyeon Jeon, Michael Aupetit, Soohyun Lee, Hyung-Kwon Ko, Youngtaek Kim, Jinwook Seo
            <br>
            <em>Arxiv 2022 (Under review)</em>
            <br>
            <div class="d-none d-sm-block">
              <!-- <a href="http://yenchenlin.me/nerf-supervision/">project page</a> / -->
              <a class="f3" href="https://arxiv.org/abs/2201.06379">paper</a> /
              <a class="f3" href="https://github.com/hj-n/distortion-aware-brushing">code</a>
              <p style="font-size:11px; margin:0px; text-align:justify;">Brushing is an everyday interaction in 2D
                scatterplots, which allows users to select and filter data points within a continuous, enclosed region
                and conduct further analysis on the points. However, such conventional brushing cannot be directly
                applied to Multidimensional Projections (MDP), as they hardly escape from False and Missing Neighbors
                distortions that make the relative positions of the points unreliable. To alleviate this problem, we
                introduce Distortion-aware brushing, a novel brushing technique for MDP. While users perform brushing,
                Distortion-aware brushing resolves distortions around currently brushed points by dynamically relocating
                points in the projection; the points whose data are close to the brushed data in the multidimensional
                (MD) space go near the corresponding brushed points in the projection, and the opposites move away.
                Hence, users can overcome distortions and readily extract out clustered data in the MD space using the
                technique. We demonstrate the effectiveness and applicability of Distortion-aware brushing through usage
                scenarios with two datasets. Finally, by conducting user studies with 30 participants, we verified that
                Distortion-aware brushing significantly outperforms previous brushing techniques in precisely separating
                clusters in the MD space, and works robustly regardless of the types or the amount of distortions in
                MDP.
              </p>
            </div>
          </td>
        </tr>

        <tr onmouseout="snc_stop()" onmouseover="snc_start()" style="vertical-align:top;">
          <td class="py-3 px-2 w-25">
            <div class="one">
              <div class="two" id="snc_image" style="opacity: 0;">
                <img src="./images/snc_after.png" class="img1">
              </div>
              <img src="./images/snc_before.png" class="img1">
            </div>
            <script type="text/javascript">
              function snc_start() {
                document.getElementById('snc_image').style.opacity = "1";
              }

              function snc_stop() {
                document.getElementById('snc_image').style.opacity = "0";
              }
              snc_stop()
            </script>
          </td>
          <td class="py-3 w-75" style="padding-left:15px;">
            <strong>Measuring and explaining the inter-cluster reliability of multidimensional projections</strong>
            <br>
            Hyeon Jeon, Hyung-Kwon Ko, Jaemin Jo, Youngtaek Kim, Jinwook Seo
            <br>
            <em>TVCG 2021</em>
            <br>
            <div class="d-none d-sm-block">
              <!-- <a href="http://yenchenlin.me/nerf-supervision/">project page</a> / -->
              <a class="f3" href="https://arxiv.org/abs/2107.07859">paper</a> /
              <a class="f3" href="https://github.com/hj-n/steadiness-cohesiveness">code</a> /
              <a class="f3" href="https://www.youtube.com/watch?v=_UdT0A1ByKE">video</a> /
              <a class="f3" href="./data/snc.bib">bibtex</a> /
              <a class="f3" href="https://doi.org/10.1109/TVCG.2021.3114833">doi</a> /
              <a class="f3"
                href="https://medium.com/snu-aiis-blog/measuring-and-explaining-the-inter-cluster-reliability-of-multidimensional-projections-ec07f4dcb153">post</a>
              <p style="font-size:11px; margin:0px; text-align:justify;">We propose Steadiness and Cohesiveness, two
                novel metrics to measure the inter-cluster reliability of multidimensional projection (MDP),
                specifically how well the inter-cluster structures are preserved between the original high-dimensional
                space and the low-dimensional projection space. Measuring inter-cluster reliability is crucial as it
                directly affects how well inter-cluster tasks (e.g., identifying cluster relationships in the original
                space from a projected view) can be conducted; however, despite the importance of inter-cluster tasks,
                we found that previous metrics, such as Trustworthiness and Continuity, fail to measure inter-cluster
                reliability. Our metrics consider two aspects of the inter-cluster reliability: Steadiness measures the
                extent to which clusters in the projected space form clusters in the original space, and Cohesiveness
                measures the opposite. They extract random clusters with arbitrary shapes and positions in one space and
                evaluate how much the clusters are stretched or dispersed in the other space. Furthermore, our metrics
                can quantify pointwise distortions, allowing for the visualization of inter-cluster reliability in a
                projection, which we call a reliability map. Through quantitative experiments, we verify that our
                metrics precisely capture the distortions that harm inter-cluster reliability while previous metrics
                have difficulty capturing the distortions. A case study also demonstrates that our metrics and the
                reliability map 1) support users in selecting the proper projection techniques or hyperparameters and 2)
                prevent misinterpretation while performing inter-cluster tasks, thus allow an adequate identification of
                inter-cluster structure.</p>
            </div>
          </td>
        </tr>

        <tr onmouseout="invoice_stop()" onmouseover="invoice_start()" style="vertical-align:top;">
          <td class="py-3 px-2 w-25">
            <div class="one">
              <div class="two" id='invoice'><video width=100% height=100% muted autoplay loop>
                  <source src="images/invoice_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video></div>
              <img src='images/invoice_before.png' class="img1">
            </div>
            <script type="text/javascript">
              function invoice_start() {
                document.getElementById('invoice').style.opacity = "1";
              }

              function invoice_stop() {
                document.getElementById('invoice').style.opacity = "0";
              }
              invoice_stop()
            </script>
          </td>
          <td class="py-3 w-75" style="padding-left:15px;">
            <strong>Mixed-Initiative Approach to Extract Data from Pictures of Medical Invoice</strong>
            <br>
            Seokweon Jung, Kiroong Choe, Seokhyeon Park, Hyung-Kwon Ko, Youngtaek Kim, Jinwook Seo
            <br>
            <em>PacificVis 2021 short</em>
            <br>
            <div class="d-none d-sm-block">
              <a class="f3" href="./data/invoice.pdf">paper</a> /
              <a class="f3" href="https://www.youtube.com/watch?v=W3l94Q4UOPw">video</a> /
              <a class="f3" href="./data/invoice.bib">bibtex</a> /
              <a class="f3" href="https://doi.org/10.1109/PacificVis52677.2021.00022">doi</a>
              <p style="font-size:11px; margin:0px; text-align:justify;">Extracting data from pictures of medical
                records is a common task in the insurance industry as the patients often send their medical invoices
                taken by smartphone
                cameras. However, the overall process is still challenging to be fully automated because of low image
                quality and variation of templates that exist in the status quo. In this paper, we propose a
                mixed-initiative pipeline for extracting data from pictures of medical invoices, where
                deep-learning-based automatic prediction models and task-specific heuristics work together under the
                mediation of a user. In the user study with 12 participants, we confirmed our mixed-initiative approach
                can supplement the drawbacks of a fully automated approach within an acceptable completion time. We
                further discuss the findings, limitations, and future works for designing a mixed-initiative system to
                extract data from pictures of a complicated table.</p>
            </div>
          </td>
        </tr>

        <tr onmouseout="pumap_stop()" onmouseover="pumap_start()" style="vertical-align:top;">
          <td class="py-3 px-2 w-25">
            <div class="one">
              <div class="two" id='pumap'><video width=100% height=100% muted autoplay loop>
                  <source src="images/pumap_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video></div>
              <img src='images/pumap_before.png' class="img1">
            </div>
            <script type="text/javascript">
              function pumap_start() {
                document.getElementById('pumap').style.opacity = "1";
              }

              function pumap_stop() {
                document.getElementById('pumap').style.opacity = "0";
              }
              pumap_stop()
            </script>
          </td>
          <td class="py-3 w-75" style="padding-left:15px;">
            <strong>Progressive Uniform Manifold Approximation and Projection</strong>
            <br>
            Hyung-Kwon Ko, Jaemin Jo, Jinwook Seo
            <br>
            <em>EuroVis 2020 short</em>
            <br>
            <div class="d-none d-sm-block">
              <a class="f3" href="./data/pumap.pdf">paper</a> /
              <a class="f3" href="https://github.com/hyungkwonko/progressive-umap">code</a> /
              <a class="f3" href="https://youtu.be/edIPfDIH1p0?t=4669">video</a> /
              <a class="f3" href="./data/pumap.bib">bibtex</a> /
              <a class="f3" href="https://doi.org/10.2312/evs.20201061">doi</a>
              <p style="font-size:11px; margin:0px; text-align:justify;">We present a progressive algorithm for the
                Uniform Manifold Approximation and Projection (UMAP), called the Progressive UMAP. Based on the theory
                of Riemannian geometry and algebraic topology, UMAP is an emerging dimensionality reduction technique
                that offers better versatility and stability than t-SNE. Although UMAP is also more efficient than
                t-SNE, it still suffers from an initial delay of a few minutes to produce the first projection, which
                limits its use in interactive data exploration. To tackle this problem, we improve the sequential
                computations in UMAP by making them progressive, which allows people to incrementally append a batch of
                data points into the projection at the desired pace. In our experiment with the Fashion MNIST dataset,
                we found that Progressive UMAP could generate the first approximate projection within a few seconds
                while also sufficiently capturing the important structures of the high-dimensional dataset.</p>
            </div>
          </td>
        </tr>
      </tbody>
    </table>
  </div>

  <div class="container my-2 py-3" style="max-width: 800px;">
    <h4>PROJECTS</h4>
    <table>
      <tbody>
        <tr onmouseout="sketch_stop()" onmouseover="sketch_start()" style="vertical-align:top;">
          <td class="py-3 px-2 w-25">
            <div class="one">
              <div class="two" id='sketch'><video width=100% height=100% muted autoplay loop>
                  <source src="images/sketch_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video></div>
              <img src='images/sketch_before.png' class="img1">
            </div>
            <script type="text/javascript">
              function sketch_start() {
                document.getElementById('sketch').style.opacity = "1";
              }

              function sketch_stop() {
                document.getElementById('sketch').style.opacity = "0";
              }
              sketch_stop()
            </script>
          </td>
          <td class="py-3 w-75" style="padding-left:15px;">
            <strong>Abstract Sketch to Character</strong>
            <br>
            <em>Spring 2022</em>
            <br>
            <div class="d-none d-sm-block">
              <p style="margin:0px; text-align:justify;">Convert human-drawn abstract sketch image to an anime character
                with varying styles</p>
            </div>
          </td>
        </tr>

        <tr onmouseout="pong_stop()" onmouseover="pong_start()" style="vertical-align:top;">
          <td class="py-3 px-2 w-25">
            <div class="one">
              <div class="two" id='pong'><video width=100% height=100% muted autoplay loop>
                  <source src="images/pong_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video></div>
              <img src='images/pong_before.png' class="img1">
            </div>
            <script type="text/javascript">
              function pong_start() {
                document.getElementById('pong').style.opacity = "1";
              }

              function pong_stop() {
                document.getElementById('pong').style.opacity = "0";
              }
              pong_stop()
            </script>
          </td>
          <td class="py-3 w-75" style="padding-left:15px;">
            <strong>Playing Atari with DQN</strong>
            <br>
            <em>Winter 2019</em>
            <br>
            <div class="d-none d-sm-block">
              <a class="f3" href="https://github.com/hyungkwonko/2019-summer-seminar/tree/master/project">code</a> /
              <a class="f3" href="https://www.youtube.com/watch?v=0UZ5U5YhGMs">video</a>
              <p style="margin:0px; text-align:justify;">Implemented DQN algorithm (Mnih et al. 2013)
                that can play one of the Atari games, 'Pong', and can beat the opponent</p>
            </div>
          </td>
        </tr>

        <tr onmouseout="music_stop()" onmouseover="music_start()" style="vertical-align:top;">
          <td class="py-3 px-2 w-25">
            <div class="one">
              <div class="two" id='music'><video width=100% height=100% muted autoplay loop>
                  <source src="images/music_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video></div>
              <img src='images/music_before.png' class="img1">
            </div>
            <script type="text/javascript">
              function music_start() {
                document.getElementById('music').style.opacity = "1";
              }

              function music_stop() {
                document.getElementById('music').style.opacity = "0";
              }
              music_stop()
            </script>
          </td>
          <td class="py-3 w-75" style="padding-left:15px;">
            <strong>Musical Structure Visualization with MIDI Data</strong>
            <br>
            <em>Fall 2019</em>
            <br>
            <div class="d-none d-sm-block">
              <!-- <a href="http://yenchenlin.me/nerf-supervision/">project page</a> / -->
              <a class="f3" href="https://hyungkwonko.github.io/M1522.000500-infovis-demo/">demo</a> /
              <a class="f3" href="https://github.com/hyungkwonko/M1522.000500-infovis">code</a> /
              <a class="f3" href="https://www.youtube.com/watch?v=2h5kbOyopqg">video</a>
              <p style="margin:0px; text-align:justify;">Information Visualization project at SNU</p>
            </div>
          </td>
        </tr>

        <tr onmouseout="novel_stop()" onmouseover="novel_start()" style="vertical-align:top;">
          <td class="py-3 px-2 w-25">
            <div class="one">
              <div class="two" id='novel'><video width=100% height=100% muted autoplay loop>
                  <source src="images/novel_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video></div>
              <img src='images/novel_before.png' class="img1">
            </div>
            <script type="text/javascript">
              function novel_start() {
                document.getElementById('novel').style.opacity = "1";
              }

              function novel_stop() {
                document.getElementById('novel').style.opacity = "0";
              }
              novel_stop()
            </script>
          </td>
          <td class="py-3 w-75" style="padding-left:15px;">
            <strong>Korean Web Novel Generation</strong>
            <br>
            <em>Spring 2018 - Summer 2018</em>
            <br>
            <div class="d-none d-sm-block">
              <!-- <a href="http://yenchenlin.me/nerf-supervision/">project page</a> / -->
              <a class="f3" href="./novel.pdf">paper</a> /
              <a class="f3" href="https://github.com/hyungkwonko/novel-generator">code</a> /
              <a class="f3" href="https://github.com/hyungkwonko/novel-generator/wiki">wiki</a> /
              <a class="f3" href="https://www.blice.co.kr/mw/detail.kt?novelId=10509">link</a> /
              <a class="f3" href="https://n.news.naver.com/mnews/article/056/0010611080?sid=001">media</a>
              <p style="margin:0px; text-align:justify;">Made deep learning-based Korean sentence recommender. Received
                20,000,000 KRW of prize money.
              </p>
            </div>
          </td>
        </tr>
      </tbody>
    </table>
  </div>

  <div class="container my-2 py-3" style="max-width: 800px;">
    <h4>MISC</h4>
    <table>
      <tbody>
        <tr onmouseout="me_stop()" onmouseover="me_start()" style="vertical-align:top;">
          <td class="py-3 px-2 w-25">
            <div class="one">
              <div class="two" id="me_image" style="opacity: 0;">
                <img src="./images/me_after.png" class="img1">
              </div>
              <img src="./images/me_before.png" class="img1">
            </div>
            <script type="text/javascript">
              function me_start() {
                document.getElementById('me_image').style.opacity = "1";
              }

              function me_stop() {
                document.getElementById('me_image').style.opacity = "0";
              }
              me_stop()
            </script>
          </td>
          <td class="py-3 w-75" style="padding-left:15px;">
            <p style="margin:0px; text-align:justify;">I love playing piano. The songs I used to play
              are <a class="f4" href="https://www.youtube.com/watch?v=gs8u8anKfdM">this</a> and
              <a class="f4" href="https://www.youtube.com/watch?v=nmdVbiHBSXQ/">this</a>.
              Also, I like swimming a lot, so I go swimming almost everyday. I am a big fan of
              Tottenham Hotspur since 2009. I own more than 400 comic books and like reading Murakami Haruki's short
              novels. I love this quote the most:
              <br><br>
              <i>Dance like nobody's watching; Love like you've never been hurt;
                Work like you don't need money; Live like it's heaven on earth.</i>
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>

  <div class="container my-2 py-3 text-center" style="max-width: 800px;">
    <table>
      <tbody>
        <tr>
          <div class="col">
            <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=F4dFwpMAAAAJ"><i
                class="fa fa-lg fa-google f1"></i></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://github.com/hyungkwonko"><i
                class="fa fa-lg fa-github f1"></i></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://www.linkedin.com/in/hyungkwonko/"><i class="fa fa-lg fa-linkedin f1"></i></a>
            <!-- <a href="https://twitter.com/hyungkwonko"><i class="fa fa-lg fa-twitter"></i></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -->
          </div>
        </tr>
        <br>
        <tr>
          <p style="font-size:small;">
            Referred to existing websites such as <a class="f4" href="https://jonbarron.info/">this</a> and
            <a class="f4" href="http://ranjithakumar.net/">this</a>.
          </p>
        </tr>
      </tbody>
    </table>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-pprn3073KE6tl6bjs2QrFaJGz5/SUsLqktiwsUTF55Jfv3qYSDhgCecCxMW52nD2"
    crossorigin="anonymous"></script>
</body>

</html>